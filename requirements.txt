# --- Core dependencies from your environment (pip section), cleaned for nvcr.io/nvidia/pytorch:24.01-py3 ---
# NOTE: The base image already includes PyTorch + CUDA. We therefore exclude torch, triton and nvidia-* CUDA wheels.
# If you want to manage PyTorch via pip instead, see the comment at the bottom.

aiohappyeyeballs==2.6.1
aiohttp==3.11.18
aiosignal==1.3.2
annotated-types==0.7.0
anyio==4.9.0
async-timeout==5.0.1
attrs==25.3.0
certifi==2025.4.26
charset-normalizer==3.4.1
click==8.1.8
coverage==7.8.2
datasets==3.5.1
dill==0.3.8
distro==1.9.0
editdistance==0.6.0
filelock==3.18.0
frozenlist==1.6.0
fsspec==2025.3.0
ftfy==6.3.1
gdown>=4.4.0
h11==0.16.0
httpcore==1.0.9
httpx==0.28.1
idna==3.10
importlib-metadata==8.7.0
iniconfig==2.1.0
iprogress==0.4
Jinja2==3.1.6
jiter==0.9.0
joblib==1.4.2
jsonschema==4.23.0
jsonschema-specifications==2025.4.1
langcodes==3.5.0
language-data==1.3.0
litellm==1.67.4.post1
locate==1.1.1
marisa-trie==1.2.1
MarkupSafe==3.0.2
mpmath==1.3.0
msgpack==1.1.0
multidict==6.4.3
multiprocess==0.70.16
networkx==3.4.2
nltk==3.9.1
# (Excluded) nvidia-* CUDA wheels provided by the base image
pandas==2.2.3
propcache==0.3.1
protobuf==4.25.7
pyarrow==20.0.0
pydantic==2.11.3
pydantic-core==2.33.1
pytest==8.3.5
pytest-cov==6.1.1
python-dotenv==1.1.0
pytz==2025.2
PyYAML==6.0.2
referencing==0.36.2
regex==2024.11.6
requests==2.32.3
rpds-py==0.24.0
safetensors==0.5.3
sentencepiece==0.2.0
sniffio==1.3.1
sympy==1.14.0
tenacity==8.5.0
tiktoken==0.9.0
tokenizers==0.21.1
# (Excluded) torch==2.7.0  # comes from base image; enable below if you switch base image
tqdm==4.67.1
transformers==4.51.3
# (Excluded) triton==3.3.0   # comes with torch wheels
types-requests==2.32.0.20250328
typing-inspection==0.4.0
tzdata==2025.2
urllib3==2.4.0
wordfreq==3.1.1
xxhash==3.5.0
yarl==1.20.0
zipp==3.21.0
spacy>=3.4.0
wmd==1.3.2
cdifflib>=1.2.0
sentence-transformers>=2.2.0
python-box>=6.0.0
vllm>=0.2.0
ray>=2.0.0
openai>=1.0.0
ollama>=0.3.0
git+https://github.com/dsbowen/strong_reject.git@main
datasets>=2.0.0
bitsandbytes>=0.40.0

# --- Additions from conda section that are pip-available and useful here ---
accelerate==0.34.2
anthropic==0.50.0
beautifulsoup4==4.12.3
bottleneck==1.4.2
debugpy==1.8.11
gitpython==3.1.44
huggingface-hub==0.30.2
ipykernel==6.29.5
ipython==8.30.0
matplotlib==3.10.0
numpy==1.26.4
Pillow==11.1.0
psutil==5.9.0
Pygments==2.19.1
seaborn==0.13.2
sentry-sdk==2.33.0
setproctitle==1.2.3
setuptools==75.8.0
tqdm==4.67.1  # re-assert
typing-extensions==4.12.2
wandb==0.16.6

# --- If you want to manage PyTorch via pip instead of the base image ---
# 1) Change the Dockerfile base image to a plain CUDA image (or python:3.10)
# 2) Uncomment ONE of the torch lines below that matches your CUDA:
#    For CUDA 12.x (pip wheels include CUDA):
# torch==2.7.0 --index-url https://download.pytorch.org/whl/cu121
#    (This will pull a matching triton and CUDA deps; remove the nvidia-* exclusions above.)